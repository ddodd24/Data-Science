{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b34fceb",
   "metadata": {},
   "source": [
    "**Denise Dodd: Classifying Images (Convolutional Neural Network (CNN))**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611b169",
   "metadata": {},
   "source": [
    "**In this exercise, I will build a convolutional neural network (CNN) to classify handwritten digits from the MNIST dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86cc5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules.\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358e61b",
   "metadata": {},
   "source": [
    "**1) Load the MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c0ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sec 20.15.\n",
    "# Load data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\n",
    "# (data_train, target_train), (data_test, target_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf95e3bb",
   "metadata": {},
   "source": [
    "**2) Display the first five images in the training data set (see section 8.1 in the Machine Learning with Python Cookbook). Compare these to the first five training labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4157bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sec 8.1.\n",
    "# Use for loop to iterate over the first five images in the training set.\n",
    "# Preplot with 1 row and 5 cols.  Specify which image is being plotted with iamge+1.\n",
    "# Determine which image to show.  Print image in gray scale.\n",
    "# Use title to print the actual number which the images represent.\n",
    "# Turn off grids, ticks, and axis usually used in plots for ease of viewing.\n",
    "# Once the loop is complete, display image.\n",
    "for image in range(5):\n",
    "    plt.subplot(1, 5, image + 1)\n",
    "    plt.imshow(data_train[image], cmap=\"gray\")\n",
    "    plt.title(str(target_train[image]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3873ed8",
   "metadata": {},
   "source": [
    "**3) Build and train a Keras CNN classifier on the MNIST training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e34426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 90s 188ms/step - loss: 0.2410 - accuracy: 0.9279\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 0.0710 - accuracy: 0.9786\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 94s 200ms/step - loss: 0.0475 - accuracy: 0.9857\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 95s 202ms/step - loss: 0.0364 - accuracy: 0.9893\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 94s 200ms/step - loss: 0.0271 - accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c763d2d510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chap 20.\n",
    "# Start neural network.\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add 2-dimensional convolutional layer with a ReLU activation function.\n",
    "# Set the number of kernals at 64 to indicate 64 grids used on data to detect features.\n",
    "# Set size of kernals at  3X3.\n",
    "# Set image shape to represnet grayscale images.\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Add 2-dimensional MaxPooling layer for feature extraction.\n",
    "# Set pool size of 2x2.\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten to a 1 dimensional layer compatable with dense layer.\n",
    "model.add(layers.Flatten())\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "model.add(layers.Dense(units = 64, activation='relu'))\n",
    "# Add fully connected layer with a softmax activation function to assign probabilities.\n",
    "model.add(layers.Dense(units = 10, activation='softmax'))\n",
    "\n",
    "# Compile model.\n",
    "# Use categorical_crossentrophy to minimize loss.\n",
    "# Use root mean square propagation to optimize performance.\n",
    "# Use accuracy as the metric to evalute model.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Reshape training images and indicate gray scale.\n",
    "# Convert pixel data type to float and rescale to between 0 and 1.\n",
    "data_train = data_train.reshape(60000, 28, 28, 1)\n",
    "data_train = data_train.astype('float32') / 255\n",
    "\n",
    "# Reshape testing images and indicate gray scale.\n",
    "# Convert pixel data type to float and rescale to between 0 and 1.\n",
    "data_test = data_test.reshape(10000, 28, 28, 1)\n",
    "data_test = data_test.astype('float32') / 255\n",
    "\n",
    "# One-hot encode labels.\n",
    "target_train = to_categorical(target_train)\n",
    "target_test = to_categorical(target_test)\n",
    "\n",
    "# Fit the model with training data.\n",
    "# Pass data trough model 5 times (this takes awhile!)\n",
    "# Batch 128 samples at a time (used a large batch size to save on time.)\n",
    "model.fit(data_train, target_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257caf7",
   "metadata": {},
   "source": [
    "**4) Report the test accuracy of your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb9c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0475 - accuracy: 0.9848\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss and accuracy of test data.\n",
    "test_loss, test_acc = model.evaluate(data_test, target_test)\n",
    "\n",
    "# Print test accuracy rounded to 2 decimals.\n",
    "print('Test accuracy:', round(test_acc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d32175",
   "metadata": {},
   "source": [
    "**5) Display a confusion matrix on the test set classifications.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fc56a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step\n",
      "[[ 976    0    1    0    0    2    0    1    0    0]\n",
      " [   0 1128    3    1    0    0    2    0    1    0]\n",
      " [   2    2 1013    2    3    1    2    5    2    0]\n",
      " [   0    0    0 1001    0    3    0    4    2    0]\n",
      " [   0    0    0    0  981    0    0    0    0    1]\n",
      " [   1    0    0    8    0  881    2    0    0    0]\n",
      " [   7    2    0    1    1    2  944    1    0    0]\n",
      " [   1    1   10    1    1    0    0 1013    1    0]\n",
      " [   6    0    5    3    2    4    1    4  944    5]\n",
      " [   1    3    0    3   15    5    0   10    5  967]]\n"
     ]
    }
   ],
   "source": [
    "# Use model to find predicted probabilities of test images.\n",
    "# Store the highest probabilities in numpy arrays.\n",
    "test_pred = model.predict(data_test)\n",
    "test_pred_labels = np.argmax(test_pred, axis=1)\n",
    "test_target_test = np.argmax(target_test, axis=1)\n",
    "print(confusion_matrix(test_target_test, test_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fece69",
   "metadata": {},
   "source": [
    "**6) Summarize results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3cff05",
   "metadata": {},
   "source": [
    "Overall, the model has an accuracy of 98%.  I likly could have improved this accuracy by raising the epoch value when I fitted the model but I choose a lower value for the sake of time.  I also could have lowered the batch size to increase accuracy but I was comfortable with the accuracy value of 98% for the purposes of the exercise.\n",
    "\n",
    "The confusion matrix furthur explains the accuracy value by detailing performance on each class.  The diagonal numbers represent correct classifications.  The low values outside of the middle diagonal repesenting misclassifications show that most predicitions were classified correct.\n",
    "\n",
    "With the results shown by the accuracy percentage and confusion matrix, I would be comfortable using the model to interpret handwirtten numbers in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78b830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
